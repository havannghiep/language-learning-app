import streamlit as st
import pandas as pd
import random
import re
import sqlite3
from datetime import datetime
import os
from gtts import gTTS
import tempfile

# Th√™m th∆∞ vi·ªán x·ª≠ l√Ω file
try:
    import PyPDF2
    from docx import Document
except ImportError:
    PyPDF2 = None
    Document = None

# T·ª™ ƒêI·ªÇN TI·∫æNG NGA - VI·ªÜT
RUSSIAN_DICTIONARY = {
    "–ø—Ä–∏–≤–µ—Ç": "xin ch√†o", "—Å–ø–∞—Å–∏–±–æ": "c·∫£m ∆°n", "–¥–∞": "c√≥", "–Ω–µ—Ç": "kh√¥ng",
    "—Ö–æ—Ä–æ—à–æ": "t·ªët", "–ø–ª–æ—Ö–æ": "x·∫•u", "–¥–æ–º": "nh√†", "–∫–Ω–∏–≥–∞": "s√°ch",
    "–≤–æ–¥–∞": "n∆∞·ªõc", "—á–µ–ª–æ–≤–µ–∫": "ng∆∞·ªùi", "–¥–µ–Ω—å": "ng√†y", "–Ω–æ—á—å": "ƒë√™m",
    "–≤—Ä–µ–º—è": "th·ªùi gian", "–∂–∏–∑–Ω—å": "cu·ªôc s·ªëng", "–≥–æ–¥": "nƒÉm", "–¥–µ–ª–æ": "c√¥ng vi·ªác",
    "—Ä—É–∫–∞": "tay", "–≥–ª–∞–∑": "m·∫Øt", "–≥–æ—Ä–æ–¥": "th√†nh ph·ªë", "–¥—Ä—É–≥": "b·∫°n",
    "—Å—Ç–æ–ª": "b√†n", "—Å—Ç—É–ª": "gh·∫ø", "–æ–∫–Ω–æ": "c·ª≠a s·ªï", "–¥–≤–µ—Ä—å": "c·ª≠a",
}

# T·ª™ ƒêI·ªÇN TI·∫æNG TRUNG - VI·ªÜT
CHINESE_DICTIONARY = {
    "‰Ω†Â•Ω": "xin ch√†o", "Ë∞¢Ë∞¢": "c·∫£m ∆°n", "ÊòØ": "c√≥", "‰∏çÊòØ": "kh√¥ng",
    "Â•Ω": "t·ªët", "‰∏çÂ•Ω": "kh√¥ng t·ªët", "ÂÆ∂": "nh√†", "‰π¶": "s√°ch",
    "Ê∞¥": "n∆∞·ªõc", "‰∫∫": "ng∆∞·ªùi", "Â§©": "ng√†y", "Êôö‰∏ä": "bu·ªïi t·ªëi",
    "Êó∂Èó¥": "th·ªùi gian", "ÁîüÊ¥ª": "cu·ªôc s·ªëng", "Âπ¥": "nƒÉm", "Â∑•‰Ωú": "c√¥ng vi·ªác",
    "Êâã": "tay", "ÁúºÁùõ": "m·∫Øt", "ÂüéÂ∏Ç": "th√†nh ph·ªë", "ÊúãÂèã": "b·∫°n",
    "Ê°åÂ≠ê": "b√†n", "Ê§ÖÂ≠ê": "gh·∫ø", "Á™óÊà∑": "c·ª≠a s·ªï", "Èó®": "c·ª≠a",
    "ÊàøÈó¥": "ph√≤ng", "ÂÖ¨ÂØì": "cƒÉn h·ªô", "Ë°óÈÅì": "ƒë∆∞·ªùng ph·ªë", "Ê±ΩËΩ¶": "xe h∆°i",
    "ËØç": "t·ª´", "Âú∞Êñπ": "n∆°i", "ËÑ∏": "khu√¥n m·∫∑t", "Â•≥‰∫∫": "ph·ª• n·ªØ",
    "Áî∑‰∫∫": "ƒë√†n √¥ng", "Â≠©Â≠ê": "tr·∫ª em", "Á≥ªÁªü": "h·ªá th·ªëng", "Êï∞Â≠ó": "s·ªë",
    "Â§¥": "ƒë·∫ßu", "ËÑö": "ch√¢n", "Á±ªÂûã": "lo·∫°i", "Ê≥ïÂæã": "lu·∫≠t",
    "ÈóÆÈ¢ò": "c√¢u h·ªèi", "Ëæπ": "ph√≠a", "ÂõΩÂÆ∂": "ƒë·∫•t n∆∞·ªõc", "‰∏ñÁïå": "th·∫ø gi·ªõi",
    "ÊÉÖÂÜµ": "t√¨nh hu·ªëng", "Â£∞Èü≥": "gi·ªçng n√≥i", "Âå∫Âüü": "khu v·ª±c", "ÊñáÁ´†": "b√†i b√°o",
    "ÁªÑ": "nh√≥m", "ÂÖ¨Âè∏": "c√¥ng ty", "ËøáÁ®ã": "qu√° tr√¨nh", "Êù°‰ª∂": "ƒëi·ªÅu ki·ªán",
    "ÁªìÊûú": "k·∫øt qu·∫£", "ÊùÉÂäõ": "quy·ªÅn l·ª±c", "ÁîµÂΩ±": "phim", "Èü≥‰πê": "√¢m nh·∫°c",
    "ÂâßÈô¢": "nh√† h√°t", "ËØ≠Ë®Ä": "ng√¥n ng·ªØ", "Ê∞îÂë≥": "m√πi", "Âë≥ÈÅì": "v·ªã",
    "È¢úËâ≤": "m√†u s·∫Øc", "Â§ßÂ∞è": "k√≠ch th∆∞·ªõc", "ÂΩ¢Áä∂": "h√¨nh d·∫°ng", "Áä∂ÊÄÅ": "t√¨nh tr·∫°ng",
    "ÊÄßË¥®": "t√≠nh ch·∫•t", "Êó∂Êúü": "th·ªùi k·ª≥", "Êó∂Âàª": "kho·∫£nh kh·∫Øc", "ÁõÆÊ†á": "m·ª•c ti√™u",
    "Áè≠Á∫ß": "l·ªõp", "ÂéüÂõ†": "nguy√™n nh√¢n", "ÁªìËÆ∫": "k·∫øt lu·∫≠n", "ÁªèÈ™å": "kinh nghi·ªám",
    "ËÅîÁ≥ª": "li√™n k·∫øt", "Ê∞¥Âπ≥": "m·ª©c ƒë·ªô", "ÁôæÂàÜÊØî": "ph·∫ßn trƒÉm", "Ëß£ÂÜ≥": "gi·∫£i ph√°p",
    "Êî∂ÂÖ•": "thu nh·∫≠p", "ÊîØÂá∫": "chi ph√≠", "Èì∂Ë°å": "ng√¢n h√†ng", "Èí±": "ti·ªÅn",
    "‰ª∑Ê†º": "gi√°", "ËÆ°Âàí": "k·∫ø ho·∫°ch", "Êä•Âëä": "b√°o c√°o", "‰∫ßÂìÅ": "s·∫£n ph·∫©m",
    "ÊäÄÊúØ": "c√¥ng ngh·ªá", "‰ø°ÊÅØ": "th√¥ng tin", "ÁÇπ": "ƒëi·ªÉm", "Á∫ø": "ƒë∆∞·ªùng",
    "ÊâãÊÆµ": "ph∆∞∆°ng ti·ªán", "ÂºÄÂßã": "b·∫Øt ƒë·∫ßu", "ÁªìÊùü": "k·∫øt th√∫c", "ÈÉ®ÂàÜ": "ph·∫ßn",
    "ÈÄâÊã©": "l·ª±a ch·ªçn", "ÊòüÊúü": "tu·∫ßn", "Êúà": "th√°ng", "‰∏ñÁ∫™": "th·∫ø k·ª∑",
    "Ë∑Ø": "con ƒë∆∞·ªùng", "ÊñπÊ≥ï": "ph∆∞∆°ng ph√°p", "Á±ªÂûã": "ki·ªÉu", "ÂéüÂàô": "nguy√™n t·∫Øc",
    "‰æãÂ≠ê": "v√≠ d·ª•", "Êù•Ê∫ê": "ngu·ªìn", "‰∫ãÂÆû": "s·ª± th·∫≠t", "‰∫ã‰ª∂": "s·ª± ki·ªán",
    "ÂØπË±°": "ƒë·ªëi t∆∞·ª£ng", "ÂÖ¨Ê∞ë": "c√¥ng d√¢n", "È¢ÜÂúü": "l√£nh th·ªï", "Èù¢ÁßØ": "di·ªán t√≠ch",
    "‰∫∫Âè£": "d√¢n s·ªë", "È¢ÑÁÆó": "ng√¢n s√°ch", "È°πÁõÆ": "d·ª± √°n", "Á®ãÂ∫è": "ch∆∞∆°ng tr√¨nh",
    "ÁªÑÁªá": "t·ªï ch·ª©c", "Ê¥ªÂä®": "ho·∫°t ƒë·ªông", "ÂèëÂ±ï": "ph√°t tri·ªÉn", "Â∏ÇÂú∫": "th·ªã tr∆∞·ªùng",
    "‰ºÅ‰∏ö": "doanh nghi·ªáp", "ÂïÜÂìÅ": "h√†ng h√≥a", "ÊäïËµÑ": "ƒë·∫ßu t∆∞", "ËµÑÊú¨": "v·ªën",
    "ËµÑÊ∫ê": "t√†i nguy√™n", "Âà©Ê∂¶": "l·ª£i nhu·∫≠n", "Á®é": "thu·∫ø", "ÁªèÊµé": "kinh t·∫ø",
    "ÊñáÂåñ": "vƒÉn h√≥a", "Ëâ∫ÊúØ": "ngh·ªá thu·∫≠t", "ÊñáÂ≠¶": "vƒÉn h·ªçc", "ÁßëÂ≠¶": "khoa h·ªçc",
    "ÊïôËÇ≤": "gi√°o d·ª•c", "ÂÅ•Â∫∑": "s·ª©c kh·ªèe", "ËøêÂä®": "th·ªÉ thao", "‰ºëÊÅØ": "ngh·ªâ ng∆°i",
    "ÊóÖË°å": "du l·ªãch", "ÂÖ≥Á≥ª": "m·ªëi quan h·ªá", "‰ΩçÁΩÆ": "v·ªã tr√≠", "ÂäüËÉΩ": "ch·ª©c nƒÉng",
    "ÁªìÊûÑ": "c·∫•u tr√∫c", "ÂÜÖÂÆπ": "n·ªôi dung", "Âü∫Á°Ä": "c∆° s·ªü", "ÊåáÊ†á": "ch·ªâ s·ªë",
    "Áä∂ÊÄÅ": "tr·∫°ng th√°i", "Ê†áÂáÜ": "ti√™u ch√≠", "Âõ†Á¥†": "y·∫øu t·ªë", "Âä®ÊÄÅ": "ƒë·ªông l·ª±c",
    "Ë∂ãÂäø": "xu h∆∞·ªõng", "ÂâçÊôØ": "tri·ªÉn v·ªçng", "ÊàòÁï•": "chi·∫øn l∆∞·ª£c", "Ê¶ÇÂøµ": "kh√°i ni·ªám",
    "Êú∫Âà∂": "c∆° ch·∫ø", "ÂÖÉÁ¥†": "y·∫øu t·ªë", "Âçï‰Ωç": "ƒë∆°n v·ªã", "ÁéØÂ¢É": "m√¥i tr∆∞·ªùng",
    "ÊÉÖÂÜµ": "t√¨nh hu·ªëng", "ÈÄâÈ°π": "ph∆∞∆°ng √°n", "ÁâàÊú¨": "phi√™n b·∫£n", "Ê®°Âûã": "m√¥ h√¨nh",
    "ÊñπÊ°à": "s∆° ƒë·ªì", "ÂõæË°®": "ƒë·ªì th·ªã", "ÂõæË°®": "bi·ªÉu ƒë·ªì", "Ë°®": "b·∫£ng",
    "Êñá‰ª∂": "t√†i li·ªáu", "Ë°å‰∏ö": "ng√†nh", "ÈÉ®Èó®": "khu v·ª±c", "ÊñπÂêë": "h∆∞·ªõng",
    "Â§çÊùÇ": "ph·ª©c h·ª£p", "‰ΩìÁßØ": "kh·ªëi l∆∞·ª£ng", "Ë¥®Èáè": "kh·ªëi l∆∞·ª£ng", "ÂØÜÂ∫¶": "m·∫≠t ƒë·ªô",
    "ÈÄüÂ∫¶": "t·ªëc ƒë·ªô", "ÂéãÂäõ": "√°p su·∫•t", "Ê∏©Â∫¶": "nhi·ªát ƒë·ªô", "ÊπøÂ∫¶": "ƒë·ªô ·∫©m",
    "ÂÖâ": "√°nh s√°ng", "Â£∞Èü≥": "√¢m thanh", "ÊåØÂä®": "rung ƒë·ªông", "ËæêÂ∞Ñ": "b·ª©c x·∫°",
    "Âú∫": "tr∆∞·ªùng", "Ê≥¢": "s√≥ng", "Á≤íÂ≠ê": "h·∫°t", "ÂéüÂ≠ê": "nguy√™n t·ª≠",
    "ÂàÜÂ≠ê": "ph√¢n t·ª≠", "Áâ©Ë¥®": "ch·∫•t", "ÊùêÊñô": "v·∫≠t li·ªáu", "ÁªÜËäÇ": "chi ti·∫øt",
    "ËäÇÁÇπ": "n√∫t", "Âùó": "kh·ªëi", "ÈõÜÂêà": "t·ªï h·ª£p", "ÂÆâË£Ö": "l·∫Øp ƒë·∫∑t",
    "ËÆæÂ§á": "thi·∫øt b·ªã", "Â∑•ÂÖ∑": "c√¥ng c·ª•", "‰ª™Âô®": "d·ª•ng c·ª•", "ÂèëÂä®Êú∫": "ƒë·ªông c∆°",
    "ÂèëÁîµÊú∫": "m√°y ph√°t", "ÂèòÂéãÂô®": "m√°y bi·∫øn √°p", "ÁªßÁîµÂô®": "r∆°le", "ÂºÄÂÖ≥": "c√¥ng t·∫Øc",
    "ÊèíÂ∫ß": "·ªï c·∫Øm", "Á∫ø": "d√¢y d·∫´n", "ÁîµÁºÜ": "c√°p", "ÁªùÁºò": "c√°ch ƒëi·ªán",
    "Êé•Âú∞": "n·ªëi ƒë·∫•t", "ÁîµÂéã": "ƒëi·ªán √°p", "ÁîµÊµÅ": "d√≤ng ƒëi·ªán", "ÁîµÈòª": "ƒëi·ªán tr·ªü",
    "ÂäüÁéá": "c√¥ng su·∫•t", "ËÉΩÈáè": "nƒÉng l∆∞·ª£ng"
}


def init_database():
    """Kh·ªüi t·∫°o database"""
    conn = sqlite3.connect('learning_history.db', check_same_thread=False)
    c = conn.cursor()

    c.execute('''CREATE TABLE IF NOT EXISTS learning_history
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  word TEXT,
                  translation TEXT,
                  language TEXT,
                  correct_count INTEGER DEFAULT 0,
                  wrong_count INTEGER DEFAULT 0,
                  last_reviewed TIMESTAMP,
                  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')

    c.execute('''CREATE TABLE IF NOT EXISTS study_sessions
                 (id INTEGER PRIMARY KEY AUTOINCREMENT,
                  session_type TEXT,
                  language TEXT,
                  score INTEGER,
                  total_questions INTEGER,
                  session_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')

    conn.commit()
    conn.close()


def extract_text_from_pdf(file):
    """Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file PDF"""
    if PyPDF2 is None:
        st.error("PyPDF2 ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t! H√£y ch·∫°y: pip install PyPDF2")
        return ""

    try:
        pdf_reader = PyPDF2.PdfReader(file)
        text = ""
        for page in pdf_reader.pages:
            page_text = page.extract_text()
            if page_text:
                text += page_text + "\n"
        return text
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file PDF: {str(e)}")
        return ""


def extract_text_from_docx(file):
    """Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file DOCX"""
    if Document is None:
        st.error("python-docx ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t! H√£y ch·∫°y: pip install python-docx")
        return ""

    try:
        doc = Document(file)
        text = ""
        for paragraph in doc.paragraphs:
            if paragraph.text:
                text += paragraph.text + "\n"
        return text
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file DOCX: {str(e)}")
        return ""


def extract_text_from_txt(file):
    """Tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ file TXT"""
    try:
        return file.read().decode('utf-8')
    except UnicodeDecodeError:
        file.seek(0)
        return file.read().decode('latin-1')
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file TXT: {str(e)}")
        return ""


def extract_russian_words(text):
    """Tr√≠ch xu·∫•t t·ª´ ti·∫øng Nga t·ª´ vƒÉn b·∫£n"""
    russian_pattern = re.compile(r'[–∞-—è–ê-–Ø—ë–Å]{2,}')
    words = russian_pattern.findall(text)

    common_words = ['–∏', '–≤', '–Ω–∞', '—Å', '–ø–æ', '—É', '–æ', '–∫', '–Ω–æ', '–∞', '–∏–∑', '–æ—Ç', '–¥–æ', '–¥–ª—è']
    filtered_words = [word for word in words if word.lower() not in common_words]

    return list(set(filtered_words))


def extract_chinese_words(text):
    """Tr√≠ch xu·∫•t t·ª´ ti·∫øng Trung t·ª´ vƒÉn b·∫£n"""
    chinese_pattern = re.compile(r'[\u4e00-\u9fff]+')
    words = chinese_pattern.findall(text)

    return list(set(words))


def detect_language(text):
    """T·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ"""
    russian_chars = len(re.findall(r'[–∞-—è–ê-–Ø—ë–Å]', text))
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))

    if chinese_chars > russian_chars:
        return "chinese"
    elif russian_chars > chinese_chars:
        return "russian"
    else:
        return "unknown"


def translate_words(words, language):
    """D·ªãch t·ª´ theo ng√¥n ng·ªØ"""
    translations = {}

    if language == "russian":
        dictionary = RUSSIAN_DICTIONARY
    elif language == "chinese":
        dictionary = CHINESE_DICTIONARY
    else:
        return translations

    for word in words:
        if word in dictionary:
            translations[word] = dictionary[word]
        else:
            translations[word] = f"[Ch∆∞a d·ªãch: {word}]"

    return translations


def text_to_speech(text, lang):
    """Chuy·ªÉn vƒÉn b·∫£n th√†nh gi·ªçng n√≥i"""
    try:
        if lang == "russian":
            tts_lang = 'ru'
        elif lang == "chinese":
            tts_lang = 'zh'
        else:
            return None

        tts = gTTS(text=text, lang=tts_lang, slow=False)
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:
            tts.save(fp.name)
            return fp.name
    except Exception as e:
        st.error(f"L·ªói ph√°t √¢m: {str(e)}")
        return None


def create_quiz(translations, num_questions=10, language="russian"):
    """T·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám"""
    quiz = []
    words = list(translations.keys())

    if len(words) < 4:
        st.warning("C·∫ßn √≠t nh·∫•t 4 t·ª´ ƒë·ªÉ t·∫°o quiz!")
        return quiz

    lang_display = "Ti·∫øng Nga" if language == "russian" else "Ti·∫øng Trung"

    for _ in range(min(num_questions, len(words))):
        correct_word = random.choice(words)
        correct_answer = translations[correct_word]

        wrong_answers = []
        while len(wrong_answers) < 3:
            wrong_word = random.choice(words)
            if (wrong_word != correct_word and
                    translations[wrong_word] not in wrong_answers and
                    translations[wrong_word] != correct_answer):
                wrong_answers.append(translations[wrong_word])

        options = wrong_answers + [correct_answer]
        random.shuffle(options)

        quiz.append({
            'question': f"T·ª´ '{correct_word}' ({lang_display}) c√≥ nghƒ©a l√† g√¨?",
            'options': options,
            'correct_answer': correct_answer,
            'word': correct_word,
            'language': language
        })

    return quiz


def flashcard_view(translations, language):
    """Hi·ªÉn th·ªã ch·∫ø ƒë·ªô flashcard"""
    lang_display = "Ti·∫øng Nga" if language == "russian" else "Ti·∫øng Trung"
    st.subheader(f"üìá Flashcards - {lang_display}")

    if not translations:
        st.warning("Ch∆∞a c√≥ t·ª´ v·ª±ng. H√£y upload file ƒë·ªÉ b·∫Øt ƒë·∫ßu!")
        return

    if 'flashcard_index' not in st.session_state:
        st.session_state.flashcard_index = 0
    if 'show_translation' not in st.session_state:
        st.session_state.show_translation = False
    if 'known_words' not in st.session_state:
        st.session_state.known_words = set()

    words = list(translations.keys())
    current_index = st.session_state.flashcard_index
    current_word = words[current_index]
    current_translation = translations[current_word]

    col1, col2, col3 = st.columns([1, 2, 1])

    with col2:
        st.markdown(f"""
        <div style='border: 2px solid #4CAF50; border-radius: 10px; padding: 50px; text-align: center; background-color: #f9f9f9;'>
            <h1 style='color: #333; font-size: 2.5em;'>{current_word}</h1>
            <p style='color: #666; font-size: 1.2em;'>{lang_display}</p>
            {f"<h2 style='color: #4CAF50; font-size: 2em;'>{current_translation}</h2>" if st.session_state.show_translation else ""}
        </div>
        """, unsafe_allow_html=True)

        col_btn1, col_btn2, col_btn3 = st.columns(3)

        with col_btn1:
            if st.button("üîÑ L·∫≠t th·∫ª"):
                st.session_state.show_translation = not st.session_state.show_translation

        with col_btn2:
            if st.button("‚úÖ ƒê√£ bi·∫øt"):
                st.session_state.known_words.add(current_word)
                save_to_history(current_word, current_translation, language, True)
                st.success("ƒê√£ ƒë√°nh d·∫•u l√† ƒë√£ bi·∫øt!")

        with col_btn3:
            if st.button("üîä Ph√°t √¢m"):
                audio_file = text_to_speech(current_word, language)
                if audio_file:
                    st.audio(audio_file, format='audio/mp3')
                    os.unlink(audio_file)

        col_nav1, col_nav2, col_nav3 = st.columns([1, 2, 1])
        with col_nav1:
            if st.button("‚èÆ Tr∆∞·ªõc") and current_index > 0:
                st.session_state.flashcard_index -= 1
                st.session_state.show_translation = False
                st.rerun()

        with col_nav3:
            if st.button("Ti·∫øp ‚è≠") and current_index < len(words) - 1:
                st.session_state.flashcard_index += 1
                st.session_state.show_translation = False
                st.rerun()

        st.write(f"Th·∫ª {current_index + 1} / {len(words)}")
        progress = (current_index + 1) / len(words)
        st.progress(progress)

        st.write(f"ƒê√£ bi·∫øt: {len(st.session_state.known_words)} t·ª´")


def save_to_history(word, translation, language, is_correct=True):
    """L∆∞u t·ª´ v√†o l·ªãch s·ª≠ h·ªçc t·∫≠p"""
    conn = sqlite3.connect('learning_history.db', check_same_thread=False)
    c = conn.cursor()

    c.execute('SELECT * FROM learning_history WHERE word = ? AND language = ?', (word, language))
    existing = c.fetchone()

    if existing:
        if is_correct:
            c.execute('''UPDATE learning_history 
                        SET correct_count = correct_count + 1, last_reviewed = ?
                        WHERE word = ? AND language = ?''', (datetime.now(), word, language))
        else:
            c.execute('''UPDATE learning_history 
                        SET wrong_count = wrong_count + 1, last_reviewed = ?
                        WHERE word = ? AND language = ?''', (datetime.now(), word, language))
    else:
        c.execute('''INSERT INTO learning_history 
                    (word, translation, language, correct_count, wrong_count, last_reviewed)
                    VALUES (?, ?, ?, ?, ?, ?)''',
                  (word, translation, language, 1 if is_correct else 0, 0 if is_correct else 1, datetime.now()))

    conn.commit()
    conn.close()


def main():
    # Kh·ªüi t·∫°o database
    init_database()

    st.set_page_config(
        page_title="H·ªçc ƒêa Ng√¥n Ng·ªØ",
        page_icon="üåç",
        layout="wide"
    )

    st.title("üåç ·ª®ng d·ª•ng H·ªçc ƒêa Ng√¥n Ng·ªØ")
    st.markdown("H·ªçc **Ti·∫øng Nga** v√† **Ti·∫øng Trung** qua t√†i li·ªáu th·ª±c t·∫ø!")

    # Ki·ªÉm tra th∆∞ vi·ªán
    if PyPDF2 is None:
        st.warning("‚ö†Ô∏è Ch∆∞a c√†i ƒë·∫∑t PyPDF2. Kh√¥ng th·ªÉ ƒë·ªçc file PDF.")
    if Document is None:
        st.warning("‚ö†Ô∏è Ch∆∞a c√†i ƒë·∫∑t python-docx. Kh√¥ng th·ªÉ ƒë·ªçc file DOCX.")

    # Sidebar ch·ªçn ng√¥n ng·ªØ
    st.sidebar.title("üåê Ch·ªçn Ng√¥n Ng·ªØ")
    selected_language = st.sidebar.radio(
        "Ng√¥n ng·ªØ h·ªçc:",
        ["üá∑üá∫ Ti·∫øng Nga", "üá®üá≥ Ti·∫øng Trung"]
    )

    language = "russian" if selected_language == "üá∑üá∫ Ti·∫øng Nga" else "chinese"
    lang_display = "Ti·∫øng Nga" if language == "russian" else "Ti·∫øng Trung"

    # ƒêi·ªÅu h∆∞·ªõng
    st.sidebar.title("üéØ ƒêi·ªÅu h∆∞·ªõng")
    app_mode = st.sidebar.selectbox(
        f"Ch·∫ø ƒë·ªô h·ªçc {lang_display}:",
        ["üì§ Upload T√†i li·ªáu", "üéØ L√†m Quiz", "üìá Flashcards", "üìä Th·ªëng k√™"]
    )

    # Upload t√†i li·ªáu
    if app_mode == "üì§ Upload T√†i li·ªáu":
        st.header(f"üì§ Upload T√†i li·ªáu {lang_display}")

        uploaded_file = st.file_uploader(
            f"Ch·ªçn file {lang_display}",
            type=['pdf', 'docx', 'txt'],
            help=f"H·ªó tr·ª£ PDF, DOCX, TXT ch·ª©a vƒÉn b·∫£n {lang_display}"
        )

        if uploaded_file is not None:
            # Hi·ªÉn th·ªã th√¥ng tin file
            file_details = {
                "T√™n file": uploaded_file.name,
                "Lo·∫°i file": uploaded_file.type,
                "K√≠ch th∆∞·ªõc": f"{uploaded_file.size / 1024:.1f} KB"
            }
            st.write(file_details)

            # ƒê·ªçc file theo lo·∫°i
            with st.spinner("ƒêang ƒë·ªçc v√† x·ª≠ l√Ω file..."):
                if uploaded_file.type == "application/pdf":
                    text = extract_text_from_pdf(uploaded_file)
                elif uploaded_file.type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
                    text = extract_text_from_docx(uploaded_file)
                else:
                    text = extract_text_from_txt(uploaded_file)

            if text:
                st.success("‚úÖ ƒê√£ ƒë·ªçc file th√†nh c√¥ng!")

                # T·ª± ƒë·ªông ph√°t hi·ªán ng√¥n ng·ªØ
                detected_lang = detect_language(text)
                if detected_lang != language:
                    st.warning(f"‚ö†Ô∏è File c√≥ v·∫ª l√† {detected_lang}, nh∆∞ng b·∫°n ƒëang ch·ªçn {language}")

                # Hi·ªÉn th·ªã preview
                with st.expander("üëÄ Xem tr∆∞·ªõc vƒÉn b·∫£n"):
                    preview_text = text[:1000] + "..." if len(text) > 1000 else text
                    st.text_area("N·ªôi dung vƒÉn b·∫£n", preview_text, height=200, key="preview")

                # Tr√≠ch xu·∫•t t·ª´ v·ª±ng
                if language == "russian":
                    words = extract_russian_words(text)
                else:
                    words = extract_chinese_words(text)

                if words:
                    st.info(f"üîç T√¨m th·∫•y {len(words)} t·ª´ {lang_display}")

                    # Hi·ªÉn th·ªã m·ªôt s·ªë t·ª´ t√¨m th·∫•y
                    st.write("üìù M·ªôt s·ªë t·ª´ ƒë√£ t√¨m th·∫•y:", ", ".join(words[:20]), "..." if len(words) > 20 else "")

                    # D·ªãch t·ª´
                    if st.button(f"üöÄ D·ªãch t·ª´ v·ª±ng {lang_display}"):
                        translations = translate_words(words, language)

                        # Hi·ªÉn th·ªã k·∫øt qu·∫£
                        st.subheader(f"üìö K·∫øt qu·∫£ d·ªãch thu·∫≠t {lang_display}")
                        vocab_df = pd.DataFrame(
                            list(translations.items()),
                            columns=[lang_display, 'Ti·∫øng Vi·ªát']
                        )
                        st.dataframe(vocab_df, use_container_width=True)

                        # Th·ªëng k√™ d·ªãch thu·∫≠t
                        translated_count = sum(1 for v in translations.values() if not v.startswith("[Ch∆∞a d·ªãch:"))
                        st.success(f"‚úÖ ƒê√£ d·ªãch ƒë∆∞·ª£c {translated_count}/{len(words)} t·ª´")

                        # L∆∞u v√†o session
                        st.session_state.translations = translations
                        st.session_state.current_language = language

                        # T·∫£i xu·ªëng
                        csv = vocab_df.to_csv(index=False).encode('utf-8')
                        st.download_button(
                            f"üì• T·∫£i xu·ªëng t·ª´ v·ª±ng {lang_display}",
                            data=csv,
                            file_name=f"vocabulary_{language}.csv",
                            mime="text/csv"
                        )
                else:
                    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y t·ª´ {lang_display} trong vƒÉn b·∫£n!")

    # L√†m Quiz
    elif app_mode == "üéØ L√†m Quiz":
        st.header(f"üéØ L√†m Quiz {lang_display}")

        if 'translations' not in st.session_state or st.session_state.get('current_language') != language:
            st.warning(f"H√£y upload t√†i li·ªáu {lang_display} tr∆∞·ªõc!")
        else:
            translations = st.session_state.translations

            num_questions = st.slider(
                "S·ªë c√¢u h·ªèi:",
                min_value=5,
                max_value=min(20, len(translations)),
                value=10
            )

            if st.button("üé≤ T·∫°o Quiz M·ªõi"):
                st.session_state.quiz = create_quiz(translations, num_questions, language)
                st.session_state.quiz_answers = [None] * len(st.session_state.quiz)
                st.session_state.quiz_submitted = False

            if 'quiz' in st.session_state and st.session_state.quiz:
                st.subheader("B√†i Quiz")

                for i, q in enumerate(st.session_state.quiz):
                    st.write(f"**C√¢u {i + 1}: {q['question']}**")

                    # Ph√°t √¢m
                    col_audio, col_quiz = st.columns([1, 4])
                    with col_audio:
                        if st.button(f"üîä", key=f"audio_{i}"):
                            audio_file = text_to_speech(q['word'], language)
                            if audio_file:
                                st.audio(audio_file, format='audio/mp3')
                                os.unlink(audio_file)

                    with col_quiz:
                        user_answer = st.radio(
                            f"Ch·ªçn ƒë√°p √°n:",
                            q['options'],
                            key=f"quiz_{i}",
                            index=st.session_state.quiz_answers[i] if st.session_state.quiz_answers[
                                                                          i] is not None else 0
                        )
                        st.session_state.quiz_answers[i] = q['options'].index(user_answer)

                if st.button("üì§ N·ªôp B√†i"):
                    score = 0
                    for i, q in enumerate(st.session_state.quiz):
                        user_answer = q['options'][st.session_state.quiz_answers[i]]
                        if user_answer == q['correct_answer']:
                            score += 1
                            save_to_history(q['word'], q['correct_answer'], language, True)
                        else:
                            save_to_history(q['word'], q['correct_answer'], language, False)

                    st.session_state.quiz_submitted = True

                    st.success(f"üéâ ƒêi·ªÉm c·ªßa b·∫°n: {score}/{len(st.session_state.quiz)}")

                    # Hi·ªÉn th·ªã k·∫øt qu·∫£ chi ti·∫øt
                    with st.expander("üìã Xem chi ti·∫øt ƒë√°p √°n"):
                        for i, q in enumerate(st.session_state.quiz):
                            user_answer = q['options'][st.session_state.quiz_answers[i]]
                            is_correct = user_answer == q['correct_answer']

                            if is_correct:
                                st.write(f"‚úÖ C√¢u {i + 1}: {q['correct_answer']}")
                            else:
                                st.write(
                                    f"‚ùå C√¢u {i + 1}: ƒê√°p √°n c·ªßa b·∫°n: {user_answer} | ƒê√°p √°n ƒë√∫ng: {q['correct_answer']}")

    # Flashcards
    elif app_mode == "üìá Flashcards":
        st.header(f"üìá H·ªçc v·ªõi Flashcards {lang_display}")

        if 'translations' not in st.session_state or st.session_state.get('current_language') != language:
            st.warning(f"H√£y upload t√†i li·ªáu {lang_display} tr∆∞·ªõc!")
        else:
            flashcard_view(st.session_state.translations, language)

    # Th·ªëng k√™
    elif app_mode == "üìä Th·ªëng k√™":
        st.header("üìä Th·ªëng k√™ h·ªçc t·∫≠p")

        conn = sqlite3.connect('learning_history.db', check_same_thread=False)

        # Th·ªëng k√™ theo ng√¥n ng·ªØ
        stats_df = pd.read_sql_query('''
            SELECT language, 
                   COUNT(*) as total_words,
                   SUM(correct_count) as total_correct,
                   SUM(wrong_count) as total_wrong,
                   COUNT(CASE WHEN correct_count > wrong_count THEN 1 END) as mastered_words
            FROM learning_history 
            GROUP BY language
        ''', conn)

        if not stats_df.empty:
            st.subheader("Th·ªëng k√™ theo ng√¥n ng·ªØ")

            for _, row in stats_df.iterrows():
                lang = "Ti·∫øng Nga" if row['language'] == 'russian' else "Ti·∫øng Trung"
                accuracy = row['total_correct'] / (row['total_correct'] + row['total_wrong']) * 100 if (row[
                                                                                                            'total_correct'] +
                                                                                                        row[
                                                                                                            'total_wrong']) > 0 else 0

                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric(f"T·ªïng t·ª´ ({lang})", row['total_words'])
                with col2:
                    st.metric(f"ƒê√£ thu·ªôc ({lang})", row['mastered_words'])
                with col3:
                    st.metric(f"S·ªë c√¢u ƒë√∫ng ({lang})", row['total_correct'])
                with col4:
                    st.metric(f"T·ª∑ l·ªá ƒë√∫ng ({lang})", f"{accuracy:.1f}%")

        conn.close()


if __name__ == "__main__":
    main()